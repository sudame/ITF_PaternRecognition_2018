fc2 <- mx.symbol.FullyConnected(data, name="fc2", num_hidden=64)
act2 <- mx.symbol.Activation(fc2, name="relu2", act_type="relu")
fc3 <- mx.symbol.FullyConnected(act2, name="fc3", num_hidden=10)
softmax <- mx.symbol.SoftmaxOutput(fc3, name="sm")
devices <- mx.cpu()
mx.set.seed(0.00001)
model <- mx.model.FeedForward.create(softmax, X=train.x, y=train.y, initializer=mx.init.uniform(0.07), ctx=devices, num.round=10, array.batch.size=100, learning.rate=0.05, momentum=0.9, wd=0.00001, eval.metric=mx.metric.accuracy, epoch.end.callback=mx.callback.log.train.metric(100))
preds <- predict(model, test, ctx=devices)
pred.label <- max.col(t(preds)) - 1
sum(diag(table(test_org[, 1], pred.label))) / 1000
table(test_org[,1], pred.label)
remove(list = ls())
train <- read.csv('./data/short_prac_train.csv', header = TRUE)
test <- read.csv('data/short_prac_test.csv', header = TRUE)
train <- data.matrix(train)
test <- data.matrix(test)
train.x <- train[, -1]
train.y <- train[, 1]
test_org <- test
test <- test[, -1]
train.x <- t(train.x/255)
test <- t(test/255)
data <- mx.symbol.Variable("data")
fc1 <- mx.symbol.FullyConnected(data, name="fc1", num_hidden=128)
act1 <- mx.symbol.Activation(fc1, name="relu1", act_type="sigmoid")
fc2 <- mx.symbol.FullyConnected(data, name="fc2", num_hidden=64)
act2 <- mx.symbol.Activation(fc2, name="relu2", act_type="sigmoid")
fc3 <- mx.symbol.FullyConnected(act2, name="fc3", num_hidden=10)
softmax <- mx.symbol.SoftmaxOutput(fc3, name="sm")
devices <- mx.cpu()
mx.set.seed(0)
model <- mx.model.FeedForward.create(softmax, X=train.x, y=train.y, initializer=mx.init.uniform(0.07), ctx=devices, num.round=10, array.batch.size=100, learning.rate=0.05, momentum=0.9, wd=0.00001, eval.metric=mx.metric.accuracy, epoch.end.callback=mx.callback.log.train.metric(100))
preds <- predict(model, test, ctx=devices)
pred.label <- max.col(t(preds)) - 1
sum(diag(table(test_org[, 1], pred.label))) / 1000
table(test_org[,1], pred.label)
remove(list = ls())
train <- read.csv('./data/short_prac_train.csv', header = TRUE)
test <- read.csv('data/short_prac_test.csv', header = TRUE)
train <- data.matrix(train)
test <- data.matrix(test)
train.x <- train[, -1]
train.y <- train[, 1]
test_org <- test
test <- test[, -1]
train.x <- t(train.x/255)
test <- t(test/255)
data <- mx.symbol.Variable("data")
fc1 <- mx.symbol.FullyConnected(data, name="fc1", num_hidden=128)
act1 <- mx.symbol.Activation(fc1, name="relu1", act_type="relu")
fc2 <- mx.symbol.FullyConnected(data, name="fc2", num_hidden=64)
act2 <- mx.symbol.Activation(fc2, name="relu2", act_type="relu")
fc3 <- mx.symbol.FullyConnected(act2, name="fc3", num_hidden=10)
softmax <- mx.symbol.SoftmaxOutput(fc3, name="sm")
devices <- mx.cpu()
mx.set.seed(0)
model <- mx.model.FeedForward.create(softmax, X=train.x, y=train.y, initializer=mx.init.uniform(0.07), ctx=devices, num.round=10, array.batch.size=100, learning.rate=0.05, momentum=0.9, wd=0.00001, eval.metric=mx.metric.accuracy, epoch.end.callback=mx.callback.log.train.metric(100))
preds <- predict(model, test, ctx=devices)
pred.label <- max.col(t(preds)) - 1
sum(diag(table(test_org[, 1], pred.label))) / 1000
table(test_org[,1], pred.label)
remove(list = ls())
train <- read.csv('./data/short_prac_train.csv', header = TRUE)
test <- read.csv('data/short_prac_test.csv', header = TRUE)
train <- data.matrix(train)
test <- data.matrix(test)
train.x <- train[, -1]
train.y <- train[, 1]
test_org <- test
test <- test[, -1]
train.x <- t(train.x/255)
test <- t(test/255)
data <- mx.symbol.Variable("data")
fc1 <- mx.symbol.FullyConnected(data, name="fc1", num_hidden=128)
act1 <- mx.symbol.Activation(fc1, name="relu1", act_type="relu")
fc2 <- mx.symbol.FullyConnected(data, name="fc2", num_hidden=64)
act2 <- mx.symbol.Activation(fc2, name="relu2", act_type="relu")
fc3 <- mx.symbol.FullyConnected(act2, name="fc3", num_hidden=10)
softmax <- mx.symbol.SoftmaxOutput(fc3, name="sm")
devices <- mx.cpu()
mx.set.seed(1000)
model <- mx.model.FeedForward.create(softmax, X=train.x, y=train.y, initializer=mx.init.uniform(0.07), ctx=devices, num.round=10, array.batch.size=100, learning.rate=0.05, momentum=0.9, wd=0.00001, eval.metric=mx.metric.accuracy, epoch.end.callback=mx.callback.log.train.metric(100))
preds <- predict(model, test, ctx=devices)
pred.label <- max.col(t(preds)) - 1
sum(diag(table(test_org[, 1], pred.label))) / 1000
table(test_org[,1], pred.label)
remove(list = ls())
train <- read.csv('./data/short_prac_train.csv', header = TRUE)
test <- read.csv('data/short_prac_test.csv', header = TRUE)
train <- data.matrix(train)
test <- data.matrix(test)
train.x <- train[, -1]
train.y <- train[, 1]
test_org <- test
test <- test[, -1]
train.x <- t(train.x/255)
test <- t(test/255)
data <- mx.symbol.Variable("data")
fc1 <- mx.symbol.FullyConnected(data, name="fc1", num_hidden=128)
act1 <- mx.symbol.Activation(fc1, name="relu1", act_type="sigmoid")
fc2 <- mx.symbol.FullyConnected(data, name="fc2", num_hidden=64)
act2 <- mx.symbol.Activation(fc2, name="relu2", act_type="sigmoid")
fc3 <- mx.symbol.FullyConnected(act2, name="fc3", num_hidden=10)
softmax <- mx.symbol.SoftmaxOutput(fc3, name="sm")
devices <- mx.cpu()
mx.set.seed(1000)
model <- mx.model.FeedForward.create(softmax, X=train.x, y=train.y, initializer=mx.init.uniform(0.07), ctx=devices, num.round=10, array.batch.size=100, learning.rate=0.05, momentum=0.9, wd=0.00001, eval.metric=mx.metric.accuracy, epoch.end.callback=mx.callback.log.train.metric(100))
preds <- predict(model, test, ctx=devices)
pred.label <- max.col(t(preds)) - 1
sum(diag(table(test_org[, 1], pred.label))) / 1000
table(test_org[,1], pred.label)
train.array <- train.x
dim(train.array) <- c(28, 28, 1, ncol(train.x))
dim(train.array)
remove(list = ls())
train <- read.csv('./data/short_prac_train.csv', header = TRUE)
test <- read.csv('data/short_prac_test.csv', header = TRUE)
train <- data.matrix(train)
test <- data.matrix(test)
train.x <- train[, -1]
train.y <- train[, 1]
test_org <- test
test <- test[, -1]
train.x <- t(train.x/255)
test <- t(test/255)
data <- mx.symbol.Variable("data")
conv1 <- mx.symbol.Convolution(data=data, kernel=c(5,5), num_filter=20)
tanh1 <- mx.symbol.Activation(data=conv1, act_type="tanh")
pool1 <- mx.symbol.Pooling(data=tanh1, pool_type="max", kernel=c(2,2), stride=c(2,2))
drop1 <- mx.symbol.Dropout(data=pool1, p=0.5)
conv2 <- mx.symbol.Convolution(data=drop1, kernel=c(5,5), num_filter=50)
tanh2 <- mx.symbol.Activation(data=conv2, act_type="tanh")
pool2 <- mx.symbol.Pooling(data=tanh2, pool_type="max", kernel=c(2,2), stride=c(2,2))
drop2 <- mx.symbol.Dropout(data=plot2, p=0.5)
flatten <- mx.symbol.Flatten(data=drop2)
fc1 <- mx.symbol.FullyConnected(data=flatten, num_hidden=50)
tanh3 <- mx.symbol.Activation(data=fc1, act_type="tanh")
drop3 <- mx.symbol.Dropout(data=tanh3, p=0.5)
fc2 <- mx.symbol.FullyConnected(data=drop3, num_hidden=10)
lenet <- mx.symbol.SoftmaxOutput(data=fc2)
train.array <- train.x
dim(train.array) <- c(28, 28, 1, ncol(train.x))
test.array <- test.array
dim(test.array) <- c(28, 28, 1, ncol(test))
mx.set.seed(0)
devices = mx.cpu()
tic <- proc.time()
model.CNNtanhDrop <- mx.model.FeedForward.create(lenet, X=train.array, y=train.y, ctx=devices, num.round=30, array.batch.size=100, learning.rate=0.05, momentum=0.9, wd=0.00001, eval.metric=mx.metric.accuracy, batch.end.callback=mx.callback.log.train.metric(100))
print(proc.time - tic)
remove(list = ls())
train <- read.csv('./data/short_prac_train.csv', header = TRUE)
test <- read.csv('data/short_prac_test.csv', header = TRUE)
train <- data.matrix(train)
test <- data.matrix(test)
train.x <- train[, -1]
train.y <- train[, 1]
test_org <- test
test <- test[, -1]
train.x <- t(train.x/255)
test <- t(test/255)
data <- mx.symbol.Variable("data")
conv1 <- mx.symbol.Convolution(data=data, kernel=c(5,5), num_filter=20)
tanh1 <- mx.symbol.Activation(data=conv1, act_type="tanh")
pool1 <- mx.symbol.Pooling(data=tanh1, pool_type="max", kernel=c(2,2), stride=c(2,2))
drop1 <- mx.symbol.Dropout(data=pool1, p=0.5)
conv2 <- mx.symbol.Convolution(data=drop1, kernel=c(5,5), num_filter=50)
tanh2 <- mx.symbol.Activation(data=conv2, act_type="tanh")
pool2 <- mx.symbol.Pooling(data=tanh2, pool_type="max", kernel=c(2,2), stride=c(2,2))
drop2 <- mx.symbol.Dropout(data=plot2, p=0.5)
flatten <- mx.symbol.Flatten(data=drop2)
fc1 <- mx.symbol.FullyConnected(data=flatten, num_hidden=50)
tanh3 <- mx.symbol.Activation(data=fc1, act_type="tanh")
drop3 <- mx.symbol.Dropout(data=tanh3, p=0.5)
fc2 <- mx.symbol.FullyConnected(data=drop3, num_hidden=10)
lenet <- mx.symbol.SoftmaxOutput(data=fc2)
train.array <- train.x
dim(train.array) <- c(28, 28, 1, ncol(train.x))
test.array <- test.array
dim(test.array) <- c(28, 28, 1, ncol(test))
mx.set.seed(0)
devices = mx.cpu()
tic <- proc.time()
model.CNNtanhDrop <- mx.model.FeedForward.create(lenet, X=train.array, y=train.y, ctx=devices, num.round=30, array.batch.size=100, learning.rate=0.05, momentum=0.9, wd=0.00001, eval.metric=mx.metric.accuracy, batch.end.callback=mx.callback.log.train.metric(100))
print(proc.time() - tic)
lenet <- mx.symbol.SoftmaxOutput(data=fc2)
remove(list = ls())
train <- read.csv('./data/short_prac_train.csv', header = TRUE)
test <- read.csv('data/short_prac_test.csv', header = TRUE)
train <- data.matrix(train)
test <- data.matrix(test)
train.x <- train[, -1]
train.y <- train[, 1]
test_org <- test
test <- test[, -1]
train.x <- t(train.x/255)
test <- t(test/255)
data <- mx.symbol.Variable("data")
conv1 <- mx.symbol.Convolution(data=data, kernel=c(5,5), num_filter=20)
tanh1 <- mx.symbol.Activation(data=conv1, act_type="tanh")
pool1 <- mx.symbol.Pooling(data=tanh1, pool_type="max", kernel=c(2,2), stride=c(2,2))
drop1 <- mx.symbol.Dropout(data=pool1, p=0.5)
conv2 <- mx.symbol.Convolution(data=drop1, kernel=c(5,5), num_filter=50)
tanh2 <- mx.symbol.Activation(data=conv2, act_type="tanh")
pool2 <- mx.symbol.Pooling(data=tanh2, pool_type="max", kernel=c(2,2), stride=c(2,2))
drop2 <- mx.symbol.Dropout(data=plot2, p=0.5)
flatten <- mx.symbol.Flatten(data=drop2)
fc1 <- mx.symbol.FullyConnected(data=flatten, num_hidden=50)
tanh3 <- mx.symbol.Activation(data=fc1, act_type="tanh")
drop3 <- mx.symbol.Dropout(data=tanh3, p=0.5)
fc2 <- mx.symbol.FullyConnected(data=drop3, num_hidden=10)
lenet <- mx.symbol.SoftmaxOutput(data=fc2)
train.array <- train.x
dim(train.array) <- c(28, 28, 1, ncol(train.x))
test.array <- test.array
dim(test.array) <- c(28, 28, 1, ncol(test))
mx.set.seed(0)
devices = mx.cpu()
tic <- proc.time()
model.CNNtanhDrop <- mx.model.FeedForward.create(lenet, X=train.array, y=train.y, ctx=devices, num.round=30, array.batch.size=100, learning.rate=0.05, momentum=0.9, wd=0.00001, eval.metric=mx.metric.accuracy, batch.end.callback=mx.callback.log.train.metric(100))
print(proc.time() - tic)
remove(list = ls())
train <- read.csv('./data/short_prac_train.csv', header = TRUE)
test <- read.csv('data/short_prac_test.csv', header = TRUE)
train <- data.matrix(train)
test <- data.matrix(test)
train.x <- train[, -1]
train.y <- train[, 1]
test_org <- test
test <- test[, -1]
train.x <- t(train.x/255)
test <- t(test/255)
data <- mx.symbol.Variable("data")
conv1 <- mx.symbol.Convolution(data=data, kernel=c(5,5), num_filter=20)
tanh1 <- mx.symbol.Activation(data=conv1, act_type="tanh")
pool1 <- mx.symbol.Pooling(data=tanh1, pool_type="max", kernel=c(2,2), stride=c(2,2))
drop1 <- mx.symbol.Dropout(data=pool1, p=0.5)
conv2 <- mx.symbol.Convolution(data=drop1, kernel=c(5,5), num_filter=50)
tanh2 <- mx.symbol.Activation(data=conv2, act_type="tanh")
pool2 <- mx.symbol.Pooling(data=tanh2, pool_type="max", kernel=c(2,2), stride=c(2,2))
drop2 <- mx.symbol.Dropout(data=pool2, p=0.5)
flatten <- mx.symbol.Flatten(data=drop2)
fc1 <- mx.symbol.FullyConnected(data=flatten, num_hidden=50)
tanh3 <- mx.symbol.Activation(data=fc1, act_type="tanh")
drop3 <- mx.symbol.Dropout(data=tanh3, p=0.5)
fc2 <- mx.symbol.FullyConnected(data=drop3, num_hidden=10)
lenet <- mx.symbol.SoftmaxOutput(data=fc2)
train.array <- train.x
dim(train.array) <- c(28, 28, 1, ncol(train.x))
test.array <- test.array
dim(test.array) <- c(28, 28, 1, ncol(test))
mx.set.seed(0)
devices = mx.cpu()
tic <- proc.time()
model.CNNtanhDrop <- mx.model.FeedForward.create(lenet, X=train.array, y=train.y, ctx=devices, num.round=30, array.batch.size=100, learning.rate=0.05, momentum=0.9, wd=0.00001, eval.metric=mx.metric.accuracy, batch.end.callback=mx.callback.log.train.metric(100))
remove(list = ls())
train <- read.csv('./data/short_prac_train.csv', header = TRUE)
test <- read.csv('data/short_prac_test.csv', header = TRUE)
train <- data.matrix(train)
test <- data.matrix(test)
train.x <- train[, -1]
train.y <- train[, 1]
test_org <- test
test <- test[, -1]
train.x <- t(train.x/255)
test <- t(test/255)
data <- mx.symbol.Variable("data")
conv1 <- mx.symbol.Convolution(data=data, kernel=c(5,5), num_filter=20)
tanh1 <- mx.symbol.Activation(data=conv1, act_type="tanh")
pool1 <- mx.symbol.Pooling(data=tanh1, pool_type="max", kernel=c(2,2), stride=c(2,2))
drop1 <- mx.symbol.Dropout(data=pool1, p=0.5)
conv2 <- mx.symbol.Convolution(data=drop1, kernel=c(5,5), num_filter=50)
tanh2 <- mx.symbol.Activation(data=conv2, act_type="tanh")
pool2 <- mx.symbol.Pooling(data=tanh2, pool_type="max", kernel=c(2,2), stride=c(2,2))
drop2 <- mx.symbol.Dropout(data=pool2, p=0.5)
flatten <- mx.symbol.Flatten(data=drop2)
fc1 <- mx.symbol.FullyConnected(data=flatten, num_hidden=50)
tanh3 <- mx.symbol.Activation(data=fc1, act_type="tanh")
drop3 <- mx.symbol.Dropout(data=tanh3, p=0.5)
fc2 <- mx.symbol.FullyConnected(data=drop3, num_hidden=10)
lenet <- mx.symbol.SoftmaxOutput(data=fc2)
train.array <- train.x
dim(train.array) <- c(28, 28, 1, ncol(train.x))
test.array <- test.array
dim(test.array) <- c(28, 28, 1, ncol(test))
mx.set.seed(0)
devices = mx.cpu()
tic <- proc.time()
model.CNNtanhDrop <- mx.model.FeedForward.create(lenet, X=train.array, y=train.y, ctx=devices, num.round=30, array.batch.size=100, learning.rate=0.05, momentum=0.9, wd=0.00001, eval.metric=mx.metric.accuracy, batch.end.callback=mx.callback.log.train.metric(100))
remove(list = ls())
train <- read.csv('./data/short_prac_train.csv', header = TRUE)
test <- read.csv('data/short_prac_test.csv', header = TRUE)
train <- data.matrix(train)
test <- data.matrix(test)
train.x <- train[, -1]
train.y <- train[, 1]
test_org <- test
test <- test[, -1]
train.x <- t(train.x/255)
test <- t(test/255)
data <- mx.symbol.Variable("data")
conv1 <- mx.symbol.Convolution(data=data, kernel=c(5,5), num_filter=20)
tanh1 <- mx.symbol.Activation(data=conv1, act_type="tanh")
pool1 <- mx.symbol.Pooling(data=tanh1, pool_type="max", kernel=c(2,2), stride=c(2,2))
drop1 <- mx.symbol.Dropout(data=pool1, p=0.5)
conv2 <- mx.symbol.Convolution(data=drop1, kernel=c(5,5), num_filter=50)
tanh2 <- mx.symbol.Activation(data=conv2, act_type="tanh")
pool2 <- mx.symbol.Pooling(data=tanh2, pool_type="max", kernel=c(2,2), stride=c(2,2))
drop2 <- mx.symbol.Dropout(data=pool2, p=0.5)
flatten <- mx.symbol.Flatten(data=drop2)
fc1 <- mx.symbol.FullyConnected(data=flatten, num_hidden=50)
tanh3 <- mx.symbol.Activation(data=fc1, act_type="tanh")
drop3 <- mx.symbol.Dropout(data=tanh3, p=0.5)
fc2 <- mx.symbol.FullyConnected(data=drop3, num_hidden=10)
lenet <- mx.symbol.SoftmaxOutput(data=fc2)
train.array <- train.x
dim(train.array) <- c(28, 28, 1, ncol(train.x))
test.array <- test
dim(test.array) <- c(28, 28, 1, ncol(test))
mx.set.seed(0)
devices = mx.cpu()
tic <- proc.time()
model.CNNtanhDrop <- mx.model.FeedForward.create(lenet, X=train.array, y=train.y, ctx=devices, num.round=30, array.batch.size=100, learning.rate=0.05, momentum=0.9, wd=0.00001, eval.metric=mx.metric.accuracy, batch.end.callback=mx.callback.log.train.metric(100))
print(proc.time() - tic)
preds <- predict(model, test, ctx=devices)
preds <- predict(model.CNNtanhDrop, test, ctx=devices)
preds <- predict(model.CNNtanhDrop, test.array, ctx=devices)
pred.label <- max.col(t(preds)) - 1
sum(diag(table(test_org[, 1], pred.label))) / 1000
remove(list = ls())
train <- read.csv('./data/short_prac_train.csv', header = TRUE)
test <- read.csv('data/short_prac_test.csv', header = TRUE)
train <- data.matrix(train)
test <- data.matrix(test)
train.x <- train[, -1]
train.y <- train[, 1]
test_org <- test
test <- test[, -1]
train.x <- t(train.x/255)
test <- t(test/255)
data <- mx.symbol.Variable("data")
conv1 <- mx.symbol.Convolution(data=data, kernel=c(5,5), num_filter=20)
tanh1 <- mx.symbol.Activation(data=conv1, act_type="tanh")
pool1 <- mx.symbol.Pooling(data=tanh1, pool_type="max", kernel=c(2,2), stride=c(2,2))
# drop1 <- mx.symbol.Dropout(data=pool1, p=0.5)
conv2 <- mx.symbol.Convolution(data=pool1, kernel=c(5,5), num_filter=50)
tanh2 <- mx.symbol.Activation(data=conv2, act_type="tanh")
pool2 <- mx.symbol.Pooling(data=tanh2, pool_type="max", kernel=c(2,2), stride=c(2,2))
# drop2 <- mx.symbol.Dropout(data=pool2, p=0.5)
flatten <- mx.symbol.Flatten(data=pool2)
fc1 <- mx.symbol.FullyConnected(data=flatten, num_hidden=50)
tanh3 <- mx.symbol.Activation(data=fc1, act_type="tanh")
# drop3 <- mx.symbol.Dropout(data=tanh3, p=0.5)
fc2 <- mx.symbol.FullyConnected(data=tanh3, num_hidden=10)
lenet <- mx.symbol.SoftmaxOutput(data=fc2)
train.array <- train.x
dim(train.array) <- c(28, 28, 1, ncol(train.x))
test.array <- test
dim(test.array) <- c(28, 28, 1, ncol(test))
mx.set.seed(0)
devices = mx.cpu()
tic <- proc.time()
model.CNNtanhDrop <- mx.model.FeedForward.create(lenet, X=train.array, y=train.y, ctx=devices, num.round=30, array.batch.size=100, learning.rate=0.05, momentum=0.9, wd=0.00001, eval.metric=mx.metric.accuracy, batch.end.callback=mx.callback.log.train.metric(100))
print(proc.time() - tic)
# テストデータによる正答率の出力
preds <- predict(model.CNNtanhDrop, test.array, ctx=devices)
pred.label <- max.col(t(preds)) - 1
sum(diag(table(test_org[, 1], pred.label))) / 1000
remove(list = ls())
train <- read.csv('./data/short_prac_train.csv', header = TRUE)
test <- read.csv('data/short_prac_test.csv', header = TRUE)
train <- data.matrix(train)
test <- data.matrix(test)
train.x <- train[, -1]
train.y <- train[, 1]
test_org <- test
test <- test[, -1]
train.x <- t(train.x/255)
test <- t(test/255)
data <- mx.symbol.Variable("data")
conv1 <- mx.symbol.Convolution(data=data, kernel=c(5,5), num_filter=20)
tanh1 <- mx.symbol.Activation(data=conv1, act_type="relu")
pool1 <- mx.symbol.Pooling(data=tanh1, pool_type="max", kernel=c(2,2), stride=c(2,2))
# drop1 <- mx.symbol.Dropout(data=pool1, p=0.5)
conv2 <- mx.symbol.Convolution(data=pool1, kernel=c(5,5), num_filter=50)
tanh2 <- mx.symbol.Activation(data=conv2, act_type="relu")
pool2 <- mx.symbol.Pooling(data=tanh2, pool_type="max", kernel=c(2,2), stride=c(2,2))
# drop2 <- mx.symbol.Dropout(data=pool2, p=0.5)
flatten <- mx.symbol.Flatten(data=pool2)
fc1 <- mx.symbol.FullyConnected(data=flatten, num_hidden=50)
tanh3 <- mx.symbol.Activation(data=fc1, act_type="relu")
# drop3 <- mx.symbol.Dropout(data=tanh3, p=0.5)
fc2 <- mx.symbol.FullyConnected(data=tanh3, num_hidden=10)
lenet <- mx.symbol.SoftmaxOutput(data=fc2)
train.array <- train.x
dim(train.array) <- c(28, 28, 1, ncol(train.x))
test.array <- test
dim(test.array) <- c(28, 28, 1, ncol(test))
mx.set.seed(0)
devices = mx.cpu()
tic <- proc.time()
model.CNNtanhDrop <- mx.model.FeedForward.create(lenet, X=train.array, y=train.y, ctx=devices, num.round=30, array.batch.size=100, learning.rate=0.05, momentum=0.9, wd=0.00001, eval.metric=mx.metric.accuracy, batch.end.callback=mx.callback.log.train.metric(100))
print(proc.time() - tic)
# テストデータによる正答率の出力
preds <- predict(model.CNNtanhDrop, test.array, ctx=devices)
pred.label <- max.col(t(preds)) - 1
sum(diag(table(test_org[, 1], pred.label))) / 1000
remove(list = ls())
train <- read.csv('./data/short_prac_train.csv', header = TRUE)
test <- read.csv('data/short_prac_test.csv', header = TRUE)
train <- data.matrix(train)
test <- data.matrix(test)
train.x <- train[, -1]
train.y <- train[, 1]
test_org <- test
test <- test[, -1]
train.x <- t(train.x/255)
test <- t(test/255)
data <- mx.symbol.Variable("data")
conv1 <- mx.symbol.Convolution(data=data, kernel=c(5,5), num_filter=20)
tanh1 <- mx.symbol.Activation(data=conv1, act_type="relu")
pool1 <- mx.symbol.Pooling(data=tanh1, pool_type="max", kernel=c(2,2), stride=c(2,2))
drop1 <- mx.symbol.Dropout(data=pool1, p=0.5)
conv2 <- mx.symbol.Convolution(data=drop1, kernel=c(5,5), num_filter=50)
tanh2 <- mx.symbol.Activation(data=conv2, act_type="relu")
pool2 <- mx.symbol.Pooling(data=tanh2, pool_type="max", kernel=c(2,2), stride=c(2,2))
drop2 <- mx.symbol.Dropout(data=pool2, p=0.5)
flatten <- mx.symbol.Flatten(data=drop2)
fc1 <- mx.symbol.FullyConnected(data=flatten, num_hidden=50)
tanh3 <- mx.symbol.Activation(data=fc1, act_type="relu")
drop3 <- mx.symbol.Dropout(data=tanh3, p=0.5)
fc2 <- mx.symbol.FullyConnected(data=drop3, num_hidden=10)
lenet <- mx.symbol.SoftmaxOutput(data=fc2)
train.array <- train.x
dim(train.array) <- c(28, 28, 1, ncol(train.x))
test.array <- test
dim(test.array) <- c(28, 28, 1, ncol(test))
mx.set.seed(0)
devices = mx.cpu()
tic <- proc.time()
model.CNNtanhDrop <- mx.model.FeedForward.create(lenet, X=train.array, y=train.y, ctx=devices, num.round=30, array.batch.size=100, learning.rate=0.05, momentum=0.9, wd=0.00001, eval.metric=mx.metric.accuracy, batch.end.callback=mx.callback.log.train.metric(100))
print(proc.time() - tic)
# テストデータによる正答率の出力
preds <- predict(model.CNNtanhDrop, test.array, ctx=devices)
pred.label <- max.col(t(preds)) - 1
sum(diag(table(test_org[, 1], pred.label))) / 1000
source('~/workspace/PatternRecognition/CNN/ex3_7.R', echo=TRUE)
remove(list = ls())
# Kaggle用テストデータ設定
test.Kaggle <- read.csv('data/test.csv', header=TRUE)
test.Kaggle <- data.matrix(test.Kaggle)
test.Kaggle <- t(test.Kaggle/255)
test.array.Kaggle <- test.Kaggle
dim(test.array.Kaggle) <- c(28, 28, 1, ncol(test.Kaggle))
train <- read.csv('./data/train.csv', header = TRUE)
train <- data.matrix(train)
train.x <- train[, -1]
train.y <- train[, 1]
train.x <- t(train.x/255)
data <- mx.symbol.Variable("data")
conv1 <- mx.symbol.Convolution(data=data, kernel=c(5,5), num_filter=20)
tanh1 <- mx.symbol.Activation(data=conv1, act_type="tanh")
pool1 <- mx.symbol.Pooling(data=tanh1, pool_type="max", kernel=c(2,2), stride=c(2,2))
drop1 <- mx.symbol.Dropout(data=pool1, p=0.5)
conv2 <- mx.symbol.Convolution(data=drop1, kernel=c(5,5), num_filter=50)
tanh2 <- mx.symbol.Activation(data=conv2, act_type="tanh")
pool2 <- mx.symbol.Pooling(data=tanh2, pool_type="max", kernel=c(2,2), stride=c(2,2))
drop2 <- mx.symbol.Dropout(data=pool2, p=0.5)
flatten <- mx.symbol.Flatten(data=drop2)
fc1 <- mx.symbol.FullyConnected(data=flatten, num_hidden=50)
tanh3 <- mx.symbol.Activation(data=fc1, act_type="tanh")
drop3 <- mx.symbol.Dropout(data=tanh3, p=0.5)
fc2 <- mx.symbol.FullyConnected(data=drop3, num_hidden=10)
lenet <- mx.symbol.SoftmaxOutput(data=fc2)
train.array <- train.x
dim(train.array) <- c(28, 28, 1, ncol(train.x))
mx.set.seed(0)
devices = mx.cpu()
tic <- proc.time()
model.CNNtanhDrop <- mx.model.FeedForward.create(lenet, X=train.array, y=train.y, ctx=devices, num.round=30, array.batch.size=100, learning.rate=0.05, momentum=0.9, wd=0.00001, eval.metric=mx.metric.accuracy, batch.end.callback=mx.callback.log.train.metric(100))
remove(list = ls())
# Kaggle用テストデータ設定
test.Kaggle <- read.csv('data/test.csv', header=TRUE)
test.Kaggle <- data.matrix(test.Kaggle)
test.Kaggle <- t(test.Kaggle/255)
test.array.Kaggle <- test.Kaggle
dim(test.array.Kaggle) <- c(28, 28, 1, ncol(test.Kaggle))
train <- read.csv('./data/train.csv', header = TRUE)
train <- data.matrix(train)
train.x <- train[, -1]
train.y <- train[, 1]
train.x <- t(train.x/255)
data <- mx.symbol.Variable("data")
conv1 <- mx.symbol.Convolution(data=data, kernel=c(5,5), num_filter=20)
tanh1 <- mx.symbol.Activation(data=conv1, act_type="tanh")
pool1 <- mx.symbol.Pooling(data=tanh1, pool_type="max", kernel=c(2,2), stride=c(2,2))
drop1 <- mx.symbol.Dropout(data=pool1, p=0.5)
conv2 <- mx.symbol.Convolution(data=drop1, kernel=c(5,5), num_filter=50)
tanh2 <- mx.symbol.Activation(data=conv2, act_type="tanh")
pool2 <- mx.symbol.Pooling(data=tanh2, pool_type="max", kernel=c(2,2), stride=c(2,2))
drop2 <- mx.symbol.Dropout(data=pool2, p=0.5)
flatten <- mx.symbol.Flatten(data=drop2)
fc1 <- mx.symbol.FullyConnected(data=flatten, num_hidden=50)
tanh3 <- mx.symbol.Activation(data=fc1, act_type="tanh")
drop3 <- mx.symbol.Dropout(data=tanh3, p=0.5)
fc2 <- mx.symbol.FullyConnected(data=drop3, num_hidden=10)
lenet <- mx.symbol.SoftmaxOutput(data=fc2)
train.array <- train.x
dim(train.array) <- c(28, 28, 1, ncol(train.x))
mx.set.seed(0)
devices = mx.cpu()
tic <- proc.time()
model.CNNtanhDrop <- mx.model.FeedForward.create(lenet, X=train.array, y=train.y, ctx=devices, num.round=30, array.batch.size=100, learning.rate=0.05, momentum=0.9, wd=0.00001, eval.metric=mx.metric.accuracy, batch.end.callback=mx.callback.log.train.metric(100))
